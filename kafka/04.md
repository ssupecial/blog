# Exactly Once 구현하기 어려운 이유

## Kafka에서의 처리 보장방식
| 방식 | Kafka에서의 처리 | 결과 |
|----------|----------|----------|
| At Most Once | Consumer가 메세지를 읽기 전에 Offset 커밋 -> 실패 시 유실 가능 | 메세지가 유실될 수 있지만 중복 처리되지는 않음 |
| At Least Once   | 메세지를 처리한 후 offset 커밋 -> 실패 시 재시도 (중복 발생 가능) | 메세지가 중복처리될 수는 있지만 유실되지는 않음 |
| Exactly Once   | Kafka + 트랜잭션 API로 메세지 전송과 Offset 커밋을 원자적으로 처리 | 모든 메세지가 정확히 한 번만 처리됨 |

**여러 처리 방식 중 "Exactly Once"는 왜 어려운지 알아보자**

## Exactly Once가 어려운 이유
- 단순히 성공/실패만 확실히 구분하기 어려워서가 아니라, "시스템의 모든 단계에서 중복 없이 정확히 한 번만 처리되도록 보장"하는게 어렵기 때문이다.
- 예를 들어, 메세지를 소비해 DB에 저장하는 경우를 가정해보자.
  - Kafka에서 메세지를 읽어서, DB에 저장 요청
  - 저장 성공 여부 응답을 받기 전에 Consumer가 죽거나 네트워크가 끊긴다면?
    - Kafka에서는 "이 메세지가 처리됐는지" 확실히 모른다.
    - 재시도하면 DB에는 중복 저장될 수 있다. (제대로 저장됐는데, 저장 성공 여부 응답을 못 받아서 재시도한 경우)
- 즉, "실패를 복구"하는 로직뿐만 아니라 "중복 저장을 방지"하는 로직까지 포함되어야 Exactly Once라고 할 수 있다.

## Kafka에서 Exactly Once를 구현하는 기술들
우선, Kafka 에서의 보장은 두 가지 문제로 나뉜다.
1. Kafka에 발행(Publish)할 때의 내구성
2. Kafka에서 소비(Consumer)할 때의 보장

즉, 발행도 딱 한 번만, 소비도 딱 한 번만 되어야 Exactly Once라고 볼 수 있다.


### 1) Idempotent Producer
- Kafka 0.11부터 도입되었다.
- 메세지를 중복 전송해도 Kafka가 중복을 제거한다
- Kafka Producer는 메세지를 전송할 때마다, Producer ID + Sequence Number를 붙여서 전송한다. Broker는 이전에 본 조합이라면 무시한다.
- Producer 설정에 다음 항목을 추가<br/>`enable.idempotence=true`
- 리더 브로커가 죽더라도 괜찮은 이유
  - Kafka는 리더가 죽으면 ISR 내 팔로워 중 하나가 리더가 됨
  - 이 새로운 리더도 Producer ID + 시퀀스 번호를 알고 있음

### 2) Transactional API
- 여러 파티션에 걸쳐 메세지를 원자적으로 전송하고, Consumer Offset 커밋까지 포함해서 EOS를 구현할 수 있도록 돕는 기능
- 코드 예시
```java
producer.initTransactions();
try {
  producer.beginTransaction();
  producer.send(record1);
  producer.send(record2);
  producer.commitTransaction();
} catch(ProducerFencedException e) {
  producer.close();
} catch(KafkaException e) {
  producer.abortTransaction();
}
```
- 예시
```
트랜잭션 시작
├─ 메시지 1 → topic-A, partition-0 → 리더: broker-1
├─ 메시지 2 → topic-B, partition-2 → 리더: broker-3
├─ 메시지 3 → topic-A, partition-1 → 리더: broker-2
└─ 오프셋 커밋 → __consumer_offsets → broker-4
→ 트랜잭션 커밋 (모두 성공 or 모두 실패)
```
- Consumer 입장에서 이 메세지들을 어떻게 읽을 것인가?
  - 하나의 토픽 파티션 안에서도, 어떤 메세지를 트랜잭션 안에 있고, 어떤 메세지는 트랜잭션 바깥에 있을 수 있음.
  - 즉, 같은 파티션의 메세지들 사이에서도 일부는 아직 "커밋"되지 않았을 수 있음. 그럼 Consumer는 이 트랜잭션 메세지를 읽어도 될까? 기다려야할까?
  - 이걸 제어하는게 바로 `isolation.level` 설정


#### `isolation.level`
|옵션|설명|
|---|---|
|`read_committed`|커밋된 트랜잭션 메시지 + 일반 메시지만 읽음 (EOS 보장)|
|`read_uncommitted`|모든 메시지를 읽음 (커밋되지 않은 트랜잭션 포함)|

예를 들어, 다음과 같은 상황이라고 가정
```
offset 100: 비트랜잭션 메시지 (즉시 읽힘)
offset 101: 트랜잭션 메시지 (아직 커밋 안 됨)
offset 102: 트랜잭션 메시지 (아직 커밋 안 됨)
offset 103: 커밋된 메시지
```
| Consumer 설정  | 읽는 메시지   |
| ------- | -------------- |
| `read_uncommitted` | 전부 읽음 (100\~103)                   |
| `read_committed`   | 100, 103만 읽음 (101\~102는 건너뜀 or 대기) |

#### Producer의 커밋 VS Consumer의 커밋
**Producer의 커밋**
  - 트랜잭션 안에서 보낸 모든 메세지를 브로커가 '최종 확정'하도록 요청하는 것
  - 메세지는 이미 브로커에 기록됐지만 "트랜잭션 상태 = 미확정"
  - 커밋하면, 해당 메세지들 "이제 소비자에게 보여줘도 돼"라고 Kafka에 알려주는 것. 이 과정에서 Offset을 증가시키거나 메타데이터를 수정하는 것은 아님
  - Kafka는 내부적으로 `__transaction_state`라는 특별한 내부 토픽에 트랜잭션 커밋 상태를 기록함. 커밋하면 해당 트랜잭션 ID의 상태가 `COMMITTED`로 변경됨

**Consumer의 커밋**
  - Consumer가 메세지를 읽은 후, "나는 여기까지 읽었어"라고 Kafka에 알려주는 것
  - 커밋하면, offset을 업데이트함.
  - `__consumer_offsets`라는 특별한 내부 토픽에 Consumer offset을 기록함.

## Stream 처리에서의 Exactly Once
정리를 해보면, Exactly Once Semantic은 다음과 같다.
> "한개의 입력 데이터(record)에 대해 그 처리 결과가 딱 한 번만 반영되는 것"<br/>
> -> 중복도 없고, 유실도 없어야한다<br/>
> -> 실패가 발생해도 동일하게 보장되어야한다

### Kafka 스트림 처리의 전형적인 구조
`Read -> Process -> Write`
- Read: Kafka Topic으로부터 입력 메세지 읽기
- Process: 메세지를 처리하면서 상태를 변경
- Write: 처리 결과를 Kafka의 출력 토픽에 기록

분산 처리(멀티 노드, 병렬 실행)이 아닌 "단일 프로세스"에서는 EOS를 구현하는게 상대적으로 쉽다.<br/>
Kafka Stream 같은 프레임워크는 이 어려운 부분을 자동으로 처리해준다.
Exactly Once는 Kafka Stream 내부 동작에서만 보장된다.
즉, 다음과 같은 외부 작업은 EOS 보장 대상이 아니다.
- Kafka Streams 애플리케이션이 외부 RPC 요청을 보내서 DB를 업데이트하는 경우
- kafka Streams 바깥에서 토픽을 직접 읽고 쓰는 커스텀 클라인트를 사용하는 경우

## 세 줄 요약
1. Kafka Streams에서의 Exactly-Once란, 입력 메시지 하나에 대해 상태를 정확히 한 번만 갱신하고, 출력 메시지를 정확히 한 번만 생성하는 것을 의미하며, 이를 분산 환경에서 달성하기 위해선 idempotent producer와 transactional API를 활용한 트랜잭션 처리와 상태 동기화가 필수적이다.
2. Kafka는 트랜잭션 로그, 상태, 오프셋 모두를 Kafka 토픽에 저장하고, 트랜잭션 코디네이터를 브로커 내부에 구현함으로써, 별도의 외부 시스템 없이 단순하고 강력한 Exactly-Once 스트림 처리 구조를 완성했다.
3. EOS 보장은 Kafka Streams나 일부 Kafka Connect 등 Kafka 생태계 내에서만 가능하며, 외부 시스템과 연계하는 경우에는 별도의 처리 로직이 필요하다.

## 참고 문헌
- Confluent Blog: [Exactly-Once Semantics Are Possible: Here’s How Kafka Does It](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/)
- 더 자세히 알고싶은 경우, 다음 문서를 읽어보기를 추천한다.
  - https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8
  - Kafka의 트랜잭션 및 Exactly-Once Semantics 기능을 설계하기 위해 작성된 내부 문서로, 메시지 흐름부터 데이터 구조, RPC 설계까지 모든 세부사항을 다룬다.









