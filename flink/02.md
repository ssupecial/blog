# Flink Checkpoint가 실제로 어떻게 생겼는지 확인해보자

## Flink Checkpoint 개요

Flink를 사용하면서 체크포인트를 S3에 저장하고 있습니다.
장애복구를 위해 필수적인 기능이라는 것은 알지만, 실제로 그 내부가 어떻게 구성되어있는지 확인해본 적이 없습니다.
S3 Bucket에 실제로 어떤 폴더들이 존재하는지, 어떤 파일들로 체크포인트가 구성되는지 직접 확인하고자 합니다.

## 요약
1. 체크포인트는 `_metadata`와 여러 `uuid` 파일들로 구성됩니다.
    - `_metadata` 파일은 어떤 오퍼레이터 상태가 어떤 물리적 파일에 위치하는지 매핑해주고, 실제 상태 데이터는 uuid 파일에 저장됩니다.
2. 상태 파일은 오퍼레이터 단위로 저장되는 것이 아니라, 각 Subtask(병렬 작업자) 별로 독립적인 파일이 생성됩니다.
3. 체크포인트 파일은 직렬화된 바이너리 형태이므로 일반적인 방법으로는 읽을 수 없고 Flink API 코드를 사용해야합니다.
4. 장애 대응이나 분석을 쉽게 하기 위해, Flink 애플리케이션 코드 작성 시 `.uid("name")`을 명시적으로 설정하는 것이 좋습니다.

### 디렉토리 구조
```
/user-defined-checkpoint-dir
    /{job-id}
        |
        + --shared/
        + --taskowned/
        + --chk-1/
        + --chk-2/
        + --chk-3/
        ...    
```
- `{job_id}`
    - Job 단위로 체크포인트 경로가 분리됩니다.
- `chk-n/`
    - "n번째 체크포인트" 전용 폴더입니다.
    - Flink는 Job의 설정에 따라 주기적으로 체크포인트를 트리거하므로, 매번 새로운 체크포인트 ID를 부여합니다. (보통 1부터 증가하는 정수)
    - 보통 이 안에 해당 체크포인트의 `_metadata`가 있고, 그 체크포인트만 쓰는 전용 상태 파일이 들어갈 수 있습니다.
- `shared/`
    - 여러 체크포인트가 공유할 수 있는 파일이 들어갑니다.
    - 특히 증분(Incremental) 체크포인트에서 의미가 커집니다.
- `taskowned/`
    - JobManager가 마음대로 지우면 안되는 파일이 들어가는 폴더입니다.

### 체크포인트 구성
#### A. 메타데이터 파일
- 보통 `_metadata` 같은 이름으로 존재합니다.
- 역할은 "목차/인덱스"에 가깝습니다.
- 어떤 오퍼레이터의 상태가 어떤 물리적 파일에 저장되어 있는지에 대한 매핑 정보가 들어있습니다.
- 상태 크기가 매우 작다면(Byte 단위), 별도 파일을 만들지 않고 메타데이터 내부에 인라인으로 저장되기도 합니다.

#### B. 데이터 파일
- 실제 상태 데이터가 저장되는 파일입니다.
- State Backend 설정에 따라 파일 구성이 달라질 수 있습니다. (예: RocksDB는 SST 파일, Heap은 전용 바이너리 파일 등)

## 실습: 로컬 환경에서 체크포인트 생성하기
실제로 로컬 환경에서 코드를 실행해보고, 생성되는 파일 구조를 확인하겠습니다.
빠르게 테스트하기 위해 S3에 체크포인트를 저장하지 않고, 로컬파일시스템에 저장하겠습니다.

### 체크포인트 파일 생성
테스트를 위해 1) 지속적으로 데이터를 생성하고, 2) 상태(State)를 누적하며, 3) 로컬 폴더에 체크포인트를 저장하는 간단한 Flink Job을 작성하였습니다.

#### 1. 예시 코드 (CheckpointGenerator)
- 1초마다 숫자를 생성 (Source)
- 홀수/짝수 키별로 합계를 누적 (Stateful Operator)
- 3초마다 로컬 폴더에 체크포인트 저장
- 핵심 포인트: `.uid()` 설정을 통해 메타데이터에서 오퍼레이터를 식별하기 쉽게 만듦
```java
package org.example;

import org.apache.flink.api.common.functions.RichFlatMapFunction;
import org.apache.flink.api.common.state.ValueState;
import org.apache.flink.api.common.state.ValueStateDescriptor;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.source.SourceFunction;
import org.apache.flink.util.Collector;

public class CheckpointGenerator {

    public static void main(String[] args) throws Exception {
        // 0. _metadata 인라인 방지
        /**
        Configuration conf = new Configuration();
        conf.set(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, MemorySize.parse("0b"));
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(conf);
         */

        // 1. 실행 환경 설정
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        

        // ==========================================
        // [핵심 1] 체크포인트 활성화 및 저장소 설정
        // ==========================================
        
        // 3초마다 체크포인트를 생성하도록 설정 (테스트 목적)
        env.enableCheckpointing(3000);

        // 체크포인트가 저장될 로컬 경로 지정
        // 실제 운영 환경에서는 "s3://..." 와 같은 원격 저장소를 사용합니다.
        String checkpointPath = "file:///tmp/flink-checkpoints";
        env.getCheckpointConfig().setCheckpointStorage(new FileSystemCheckpointStorage(checkpointPath));

        // ==========================================
        // [로직] 데이터 소스 및 상태 처리
        // ==========================================

        DataStream<Long> sourceStream = env
                .addSource(new SimpleNumberSource())
                .name("Number-Source")
                .uid("source-uid"); // [핵심 2] Metadata 확인을 위해 UID 고정

        sourceStream
                .keyBy(number -> number % 2) // 홀수(1), 짝수(0) 로 키 파티셔닝
                .flatMap(new StatefulSumFunction())
                .name("Sum-Operator")
                .uid("sum-operator-uid") // [핵심 2] Metadata 확인을 위해 UID 고정
                .print();

        env.execute("Checkpoint Generator Job");
    }

    // --------------------------------------------------------
    // [Source] 1초마다 1씩 증가하는 숫자 발행
    // --------------------------------------------------------
    public static class SimpleNumberSource implements SourceFunction<Long> {
        private volatile boolean isRunning = true;
        private long counter = 1;

        @Override
        public void run(SourceContext<Long> ctx) throws Exception {
            while (isRunning) {
                // Checkpoint Lock을 사용하여 Thread-safe하게 데이터 발행
                synchronized (ctx.getCheckpointLock()) {
                    ctx.collect(counter++);
                }
                Thread.sleep(1000); 
            }
        }

        @Override
        public void cancel() {
            isRunning = false;
        }
    }

    // --------------------------------------------------------
    // [Operator] 누적 합계를 저장하는 상태(State) 함수
    // --------------------------------------------------------
    public static class StatefulSumFunction extends RichFlatMapFunction<Long, String> {
        // [핵심 3] Flink가 관리하는 상태 변수 (이 내용이 체크포인트 파일에 저장됨)
        private transient ValueState<Long> sumState;

        @Override
        public void open(Configuration parameters) {
            // 상태 정의 (이름: "running-sum")
            ValueStateDescriptor<Long> descriptor =
                    new ValueStateDescriptor<>("running-sum", Types.LONG);
            sumState = getRuntimeContext().getState(descriptor);
        }

        @Override
        public void flatMap(Long value, Collector<String> out) throws Exception {
            // 현재 상태 값 읽기 (없으면 0)
            Long currentSum = sumState.value();
            if (currentSum == null) {
                currentSum = 0L;
            }

            // 상태 업데이트 (메모리에 반영 -> 이후 체크포인트 시 파일로 기록됨)
            currentSum += value;
            sumState.update(currentSum);

            int subtask = getRuntimeContext().getIndexOfThisSubtask();

            out.collect(String.format("Key: %d, New Value: %d, Total Sum: %d, Subtask: %d",
                    value % 2, value, currentSum, subtask));
        }
    }
}
```

#### 2. 코드 실행 및 확인
위 코드를 실행하면 `Source -> keyBy() -> flatMap -> print()` 흐름으로 데이터가 처리됩니다.
- `env.enableCheckpointing(3000)`: 3초마다 JobManager가 각 TaskManager에게 "상태를 저장하라는" 신호를 보냅니다.
- `ValueState<Long> sumState`: `flatMap` 연산자는 들어온 데이터를 단순히 처리만 하는 것이 아니라, 누적 합계(running-sum)라는 정보를 기억하고 있습니다. 이 정보가 바로 체크포인트 파일 안에 바이너리 형태로 저장될 데이터입니다.
- `.uid("...")`: 나중에 생성된 `_metadata` 파일을 뜯어볼 때, 어떤 데이터가 어떤 오퍼레이터의 것인지 식별하기 위해 고유 ID를 부여했습니다. uid를 지정하지 않을 경우 Flink는 임의의 값을 부여합니다.

코드를 실행하고 기다리면, 체크포인트로 지정된 경로에 Job ID 폴더 내에 `chk-1`, `chk-2` 폴더들이 생성되는 것을 볼 수 있습니다.
```bash
# Flink Checkpoint 경로로 이동
$ cd /tmp/flink-checkpoints 

# 해당 코드를 여러 번 실행했기에 여러 개의 Job id 폴더가 생성되어있는 것을 확인할 수 있음 
$ ls -al
total 0
drwxr-xr-x  6 admin  staff  192 Dec 20 21:25 .
drwxr-xr-x  8 admin  staff  256 Dec 18 21:55 ..
drwxr-xr-x@ 5 admin  staff  160 Dec 20 21:25 02555af418cd982c64eb84dbe3505606
drwxr-xr-x@ 5 admin  staff  160 Dec 18 21:56 0b392fe9e3ce40c6f3b874870fd9b9ce
drwxr-xr-x@ 5 admin  staff  160 Dec 18 22:24 87e0a56e49e61c6ac9b3beb36a47fa07
drwxr-xr-x@ 5 admin  staff  160 Dec 20 20:58 f62d72419ffe93047cd99159b86a6ad5

# 특정 Job 폴더로 이동
$ cd 02555af418cd982c64eb84dbe3505606 

# shared와 taskowned 폴더에는 아무 파일이 없고, chk-6 폴더만 확인
$ ls -al
total 0
drwxr-xr-x@ 5 admin  staff  160 Dec 18 21:56 .
drwxr-xr-x  5 admin  staff  160 Dec 20 20:57 ..
drwxr-xr-x@ 3 admin  staff   96 Dec 18 21:56 chk-6
drwxr-xr-x@ 2 admin  staff   64 Dec 18 21:56 shared
drwxr-xr-x@ 2 admin  staff   64 Dec 18 21:56 taskowned
$ cd chk-6

# _metadata 및 체크포인트 파일이 생성되어있는 것을 확인할 수 있음
$ ls -al
total 72
drwxr-xr-x@ 11 admin  staff   352 Dec 20 21:25 .
drwxr-xr-x@  5 admin  staff   160 Dec 20 21:25 ..
-rw-r--r--@  1 admin  staff   533 Dec 20 21:25 2488526f-bcf4-488c-bc66-1515aa0d5141
-rw-r--r--@  1 admin  staff   533 Dec 20 21:25 3d6ac0ce-7e1b-48f7-b048-2e0f4c3d943b
-rw-r--r--@  1 admin  staff   533 Dec 20 21:25 44d78f79-82ac-4463-8c5d-fb64cfcfb8f8
-rw-r--r--@  1 admin  staff   567 Dec 20 21:25 5ca13890-a5cd-4539-a458-013500878255
-rw-r--r--@  1 admin  staff   533 Dec 20 21:25 8bd4e861-a55c-4d7a-9cdb-5e27b3e340b8
-rw-r--r--@  1 admin  staff   533 Dec 20 21:25 93c205e7-4ed3-4409-b2a9-94f019b2c5ca
-rw-r--r--@  1 admin  staff  2835 Dec 20 21:25 _metadata
-rw-r--r--@  1 admin  staff   533 Dec 20 21:25 a327dfca-d675-44f1-a2f7-5c6d5df6f328
-rw-r--r--@  1 admin  staff   533 Dec 20 21:25 edb47758-87f0-4519-b3d0-03f006a7f92f
``` 

#### 3. `chk-6` 폴더 내 파일 확인
- `uuid`로 구성된 파일
    - 실제 상태(State) 데이터가 직렬화되어 저장된 파일
    - 파일이 여러 개인 이유: Flink의 병렬성 때문
        - Job을 실행할 때 병렬도가 8로 설정되어있기 때문에, 8개의 Subtask로 쪼개져서 실행됨
        - 체크포인트가 수행되면 각 Subtask는 자신이 담당한 구역의 상태를 별도의 파일로 기록함
- `_metadata` 파일
    - 위의 모든 파일의 관계를 설명해주는 파일
    - 체크포인트의 설계도이자 매핑 테이블
    - 어떤 Operator의 몇 번째 Subtask가, 어떤 UUID 파일을 참조해야하는지 기록되어있음
    - Flink가 복구할 때 가장 먼저 읽는 파일


### `_metadata` 파일 확인
`_metadata` 파일은 바이너리 형식이므로 텍스트 에디터로 읽을 수 없습니다.
내용을 확인하기 위해서는 Flink 내부 API를 사용하여 바이너리 데이터를 객체로 역직렬화해야합니다.

#### 1. 예시 코드 (MetadataViewer)
Flink의 `Checkpoints.loadCheckpointMetadata` 메서드를 사용하면 메타데이터 파일을 자바 객체로 로드하여 상세 정보를 조회할 수 있습니다.

```java
public class MetadataViewer {
    public static void main(String[] args) {
        // 분석하고 싶은 _metadata 파일 경로로 수정하세요 (ex. /tmp/flink-checkpoints/chk-<N>/_metadata)
        String METADATA_PATH = "";

        System.out.println("Reading metadata from: " + METADATA_PATH);

        try (DataInputStream stream = new DataInputStream(new FileInputStream(METADATA_PATH))) {

            // 1. 메타데이터 로드
            CheckpointMetadata metadata = Checkpoints.loadCheckpointMetadata(
                    stream,
                    Thread.currentThread().getContextClassLoader(),
                    METADATA_PATH
            );

            System.out.println("========================================");
            System.out.println(" [Checkpoint ID]: " + metadata.getCheckpointId());
            System.out.println(" [Master States]: " + metadata.getMasterStates());
            System.out.println("========================================");

            // 2. 오퍼레이터별 상태 순회
            for (OperatorState operatorState : metadata.getOperatorStates()) {
                System.out.println("\n------------------------------------------------------------");
                System.out.println("[Operator ID]: " + operatorState.getOperatorID());
                System.out.println(" - Parallelism: " + operatorState.getParallelism());
                System.out.println(" - Max Parallelism: " + operatorState.getMaxParallelism());
                System.out.println("------------------------------------------------------------");

                // 3. Subtask(병렬 태스크)별 상태 상세 조회
                operatorState.getSubtaskStates().forEach((subtaskId, subtaskState) -> {
                    System.out.println("\n  >>> Subtask Index: " + subtaskId);
                    System.out.println("      (Total Size: " + subtaskState.getStateSize() + " bytes)");

                    // 3-1. Managed Keyed State (우리가 사용한 ValueState가 여기 들어감)
                    printKeyedState("Managed Keyed", subtaskState.getManagedKeyedState());

                    // 3-2. Raw Keyed State (사용자가 직접 직렬화한 경우)
                    printKeyedState("Raw Keyed", subtaskState.getRawKeyedState());

                    // 3-3. Managed Operator State (ListState 등)
                    printOperatorState("Managed Operator", subtaskState.getManagedOperatorState());

                    // 3-4. Raw Operator State
                    printOperatorState("Raw Operator", subtaskState.getRawOperatorState());
                });
            }

        } catch (IOException e) {
            System.err.println("파일을 읽는 중 에러 발생: " + e.getMessage());
            e.printStackTrace();
        }
    }

    // Keyed State (KeyBy 이후 사용되는 상태) 정보 출력
    private static void printKeyedState(String type, Collection<? extends KeyedStateHandle> handles) {
        if (handles.isEmpty()) return;

        System.out.println("      [" + type + " State]");
        for (KeyedStateHandle handle : handles) {
            System.out.println("        - KeyGroupRange: " + handle.getKeyGroupRange());

            // KeyGroupsStateHandle로 캐스팅 가능하면 파일 경로 확인 가능
            if (handle instanceof KeyGroupsStateHandle) {
                KeyGroupsStateHandle groupsHandle = (KeyGroupsStateHandle) handle;
                StreamStateHandle streamHandle = groupsHandle.getDelegateStateHandle();

                // 여기서 실제 물리 파일 경로(UUID)를 확인할 수 있음
                if (streamHandle != null) {
                    System.out.println("        - Physical File: " + streamHandle.getStreamStateHandleID());
                }
            } else {
                System.out.println("        - Handle Info: " + handle);
            }
            System.out.println("        - State Size: " + handle.getStateSize() + " bytes");
        }
    }

    // Operator State (Kafka Source Offset, ListState 등) 정보 출력
    private static void printOperatorState(String type, Collection<? extends OperatorStateHandle> handles) {
        if (handles.isEmpty()) return;

        System.out.println("      [" + type + " State]");
        for (OperatorStateHandle handle : handles) {
            StreamStateHandle streamHandle = handle.getDelegateStateHandle();
            if (streamHandle != null) {
                System.out.println("        - Physical File: " + streamHandle.getStreamStateHandleID());
            }
            System.out.println("        - State Size: " + handle.getStateSize() + " bytes");
            System.out.println("        - Handle Info: " + handle);
        }
    }
}
```

#### 2. 코드 실행 및 확인

해당 코드를 실행하면 다음과 같은 결과를 얻을 수 있습니다.
```bash
========================================
 [Checkpoint ID]: 6
 [Master States]: []
========================================

------------------------------------------------------------
[Operator ID]: 71d63d3631d5b891236e7e676b75cb78
 - Parallelism: 8
 - Max Parallelism: 128
------------------------------------------------------------

  >>> Subtask Index: 0
      (Total Size: 0 bytes)

  >>> Subtask Index: 1
      (Total Size: 0 bytes)

  >>> Subtask Index: 2
      (Total Size: 0 bytes)

  >>> Subtask Index: 3
      (Total Size: 0 bytes)

  >>> Subtask Index: 4
      (Total Size: 0 bytes)

  >>> Subtask Index: 5
      (Total Size: 0 bytes)

  >>> Subtask Index: 6
      (Total Size: 0 bytes)

  >>> Subtask Index: 7
      (Total Size: 0 bytes)

------------------------------------------------------------
[Operator ID]: bef22c5df1ab33dd94bb7a6ecac555fb
 - Parallelism: 1
 - Max Parallelism: 128
------------------------------------------------------------

------------------------------------------------------------
[Operator ID]: 91f194c2327804132a6f56c8f2ead089
 - Parallelism: 8
 - Max Parallelism: 128
------------------------------------------------------------

  >>> Subtask Index: 0
      (Total Size: 533 bytes)
      [Managed Keyed State]
        - KeyGroupRange: KeyGroupRange{startKeyGroup=0, endKeyGroup=15}
        - Physical File: file:/Users/admin/Desktop/study/big-data-learning/flink/projects/flink-example/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6/edb47758-87f0-4519-b3d0-03f006a7f92f
        - State Size: 533 bytes

  >>> Subtask Index: 1
      (Total Size: 533 bytes)
      [Managed Keyed State]
        - KeyGroupRange: KeyGroupRange{startKeyGroup=16, endKeyGroup=31}
        - Physical File: file:/Users/admin/Desktop/study/big-data-learning/flink/projects/flink-example/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6/44d78f79-82ac-4463-8c5d-fb64cfcfb8f8
        - State Size: 533 bytes

  >>> Subtask Index: 2
      (Total Size: 533 bytes)
      [Managed Keyed State]
        - KeyGroupRange: KeyGroupRange{startKeyGroup=32, endKeyGroup=47}
        - Physical File: file:/Users/admin/Desktop/study/big-data-learning/flink/projects/flink-example/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6/8bd4e861-a55c-4d7a-9cdb-5e27b3e340b8
        - State Size: 533 bytes

  >>> Subtask Index: 3
      (Total Size: 533 bytes)
      [Managed Keyed State]
        - KeyGroupRange: KeyGroupRange{startKeyGroup=48, endKeyGroup=63}
        - Physical File: file:/Users/admin/Desktop/study/big-data-learning/flink/projects/flink-example/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6/a327dfca-d675-44f1-a2f7-5c6d5df6f328
        - State Size: 533 bytes

  >>> Subtask Index: 4
      (Total Size: 533 bytes)
      [Managed Keyed State]
        - KeyGroupRange: KeyGroupRange{startKeyGroup=64, endKeyGroup=79}
        - Physical File: file:/Users/admin/Desktop/study/big-data-learning/flink/projects/flink-example/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6/93c205e7-4ed3-4409-b2a9-94f019b2c5ca
        - State Size: 533 bytes

  >>> Subtask Index: 5
      (Total Size: 567 bytes)
      [Managed Keyed State]
        - KeyGroupRange: KeyGroupRange{startKeyGroup=80, endKeyGroup=95}
        - Physical File: file:/Users/admin/Desktop/study/big-data-learning/flink/projects/flink-example/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6/5ca13890-a5cd-4539-a458-013500878255
        - State Size: 567 bytes

  >>> Subtask Index: 6
      (Total Size: 533 bytes)
      [Managed Keyed State]
        - KeyGroupRange: KeyGroupRange{startKeyGroup=96, endKeyGroup=111}
        - Physical File: file:/Users/admin/Desktop/study/big-data-learning/flink/projects/flink-example/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6/2488526f-bcf4-488c-bc66-1515aa0d5141
        - State Size: 533 bytes

  >>> Subtask Index: 7
      (Total Size: 533 bytes)
      [Managed Keyed State]
        - KeyGroupRange: KeyGroupRange{startKeyGroup=112, endKeyGroup=127}
        - Physical File: file:/Users/admin/Desktop/study/big-data-learning/flink/projects/flink-example/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6/3d6ac0ce-7e1b-48f7-b048-2e0f4c3d943b
        - State Size: 533 bytes
```

코드를 실행하니 총 3개의 Operator 정보가 출력되었습니다.
1. 첫 번째 오퍼레이터 (`71d63d3631d5b891236e7...`)
    - 특징: 병렬도는 8이지만, 모든 Subtask의 상태 크기가 0입니다.
    - 정체: Sink (`.print()`)
        - `print()` 함수는 데이터를 출력만 할 뿐, 내부적으로 저장해야할 상태(State)가 없습니다.
        - 따라서 체크포인트에 기록될 데이터도 없으므로 상태 크기가 0으로 나타납니다.
2. 두 번째 오퍼레이터 (`bef22c5df1ab33dd94bb...`)
    - 특징: 유일하게 병렬도가 1입니다.
    - 정체: Source (`SimpleNumberSource`)
        - 소스코드에서 `SourceFunction` 인터페이스를 구현했습니다. Flink에서 일반 `SourceFunction`은 병렬도 1로 고정되어 실행됩니다.
        - 소스코드에서 별도의 Offset 상태를 저장하지 않아 사이즈는 0으로 잡혔습니다.
3. 세 번째 오퍼레이터 (`91f194c2327804132a6f...`)
    - 특징: 병렬도가 8이며, `Managed Keyed State`를 가지고 있습니다.
    - 정체: FlatMap (`StatefulSumFunction`)
        - `keyBy` 이후 `ValueState`를 사용하여 합계를 구하는 오퍼레이터입니다.

#### 3. 세 번째 오퍼레이터 상세 분석
세 번째 오퍼레이터에서 하나의 Subtask만 크기가 567 bytes이고, 나머지는 모두 533 bytes인 것을 확인할 수 있습니다.

**A. 빈 껍데기 파일들 (533 bytes)**
`Subtask 0, 1, 2, 3, 4, 6, 7`
이 Subtask들은 자신에게 할당된 key가 하나도 들어오지 않았습니다.
Flink가 기본 헤더만 담긴 533 바이트짜리 파일을 강제로 생성했습니다.

**B. 진짜 데이터가 든 파일 (567 bytes)**
`Subtask 5`
소스코드에서 생성된 키 0(짝수)과 1(홀수)의 해시값이 모두 Subtask 5번의 담당 구역(KeyGroup 80~95)에 할당되었습니다.

> 결과를 보면 알 수 있듯이, Flink는 상태 파일을 오퍼레이터 단위로 생성하는 것이 아니라, Subtask 별로 쪼개어 생성합니다.
> 이러한 구조 덕분에 Flink는 추후 병렬로를 변경할 때, 거대한 파일 하나를 힘들께 쪼갤 필요 없이 각 Subtask가 소유한 파일들의 매핑만 다시 조정하면 되므로 훨씬 유연하고 빠른 확장이 가능합니다.

### 실제 상태 데이터 확인
메타데이터 파일을 확인했으니 실제 데이터는 어떻게 저장되는지 확인해봅시다.
체크포인트 파일은 직렬화된 바이너리 형태이므로 텍스트 에디터로는 내용을 볼 수 없습니다. 이때 사용하는 도구가 바로 `Flink State Processor API`입니다.
"그냥 체크포인트 안에 있는 거 다 보여줘!"라고 명령하면 좋겠지만, 불가능합니다.
파일에 저장된 `0101..` 데이터가 `Long`인지, `String`인지, 아니면 MyObject인지 Flink는 알 수 없습니다. 따라서 데이터를 읽기 위해서는 반드시 다음 두 가지 정보를 제공해야 합니다.
1. 어떤 오퍼레이터인가? (Operator ID/UID)
2. 어떤 타입인가?

#### 1. 예시 코드 (StateDataViewer)
아까 확인한 세 번째 오퍼레이터(UID: `91f1...`)의 상태를 읽어오는 코드를 작성해봅시다.
```java
public class StateDataViewer {

    // (1) KeyedStateReaderFunction: 각 key에 대해 state를 읽어서 출력 레코드를 만든다
    public static class RunningSumReader extends KeyedStateReaderFunction<Long, Tuple2<Long, Long>> {
        private transient ValueState<Long> sumState;

        @Override
        public void open(Configuration parameters) throws Exception {
            // [중요] 원본 코드와 "이름"과 "타입"이 100% 일치해야 함
            ValueStateDescriptor<Long> desc =
                    new ValueStateDescriptor<>("running-sum", Types.LONG);
            sumState = getRuntimeContext().getState(desc);
        }

        @Override
        public void readKey(Long key, Context ctx, Collector<Tuple2<Long, Long>> out) throws Exception {
            // 상태 값을 읽어서 (Key, Value) 튜플로 출력
            Long sum = sumState.value();
            out.collect(Tuple2.of(key, sum));
        }
    }

    public static void main(String[] args) throws Exception {
        // (2) DataStream API를 BATCH 실행 모드로
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setRuntimeMode(RuntimeExecutionMode.BATCH);

        // (3) 체크포인트/세이브포인트 경로 지정 (예: file:///tmp/flink-checkpoints/.../chk-8)
        String CHECKPOINT_PATH ="/tmp/flink-checkpoints/02555af418cd982c64eb84dbe3505606/chk-6";

        // (4) 원래 잡이 사용한 StateBackend와 동일해야 함
        //     별도 지정이 없으므로(로컬 기본) HashMapStateBackend로 설정
        StateBackend backend = new HashMapStateBackend();

        SavepointReader reader = SavepointReader.read(env, CHECKPOINT_PATH, backend);

        // (5) operator 식별은 UID로
        DataStream<Tuple2<Long, Long>> sums =
                reader.readKeyedState(
                        OperatorIdentifier.forUid("sum-operator-uid"),
                        // OperatorIdentifier.forUidHash("91f194c2327804132a6f56c8f2ead089"), // _metadata에서 operator ID 해시로도 가능 (단, forUidHash 함수 사용)
                        new RunningSumReader(),
                        Types.LONG,                         // Key type
                        Types.TUPLE(Types.LONG, Types.LONG) // Output type (key, sum)
                );

        sums.print();

        env.execute("StateDataViewer");
    }
}

```

> **Tip: OperatorIdentifier 주의사항**
> `OperatorIdentifier.forUid("이름")`는 원본 Job 코드에서 .uid("이름")을 명시적으로 설정했을 때만 작동합니다. 
> 만약 설정하지 않았다면 Flink가 자동으로 생성한 Hash 값을 사용해야 하므로 `forUidHash("해시값")` 메서드를 사용해야 합니다.

#### 2. 코드 실행
다음과 같은 출력 결과를 얻을 수 있습니다.
```bash
1> (1,81) # Key: 1 (홀수)의 누적 합계
1> (0,72) # Key: 0 (짝수)의 누적 합계
```

## 비고
### 사용한 소스코드
> 본 포스팅에서 사용한 예제 코드는 Github에 공개되어 있습니다. 
> 별도의 Flink 클러스터를 구축하지 않아도, IntelliJ 등의 IDE에서 바로 실행하여 테스트해 볼 수 있습니다.
- 체크포인트 파일 생성을 위한 Flink 샘플 코드
: https://github.com/ssupecial/big-data-learning/tree/main/flink/projects/flink-example
- 체크포인트 파일 확인을 위한 Flink 샘플 코드
: https://github.com/ssupecial/big-data-learning/tree/main/flink/projects/flink-metadata

### 공식 문서
> 원하는 Flink 버전을 선택하여 확인합니다.
- Flink Checkpoint 공식 문서 (1.20 ver)
: https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/ops/state/checkpoints/